{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "import urllib\n",
    "from time import sleep\n",
    "#importing geopy library\n",
    "import geocoder\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip().strip('-')\n",
    "    text = text.lower()\n",
    "    text = '_'.join(text.split(' '))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(attraction_name, city_name,country_name):\n",
    "    attraction = attraction_name + city_name + country_name\n",
    "    g = geocoder.bing(attraction, key='AgR8OLOeZgfCcu_KUf1R8Dfb4JrD0_X2UWIjPYum-aQa9vP9U_s42HjbiZVOYbTI')\n",
    "    location = g.json\n",
    "    if location == None:\n",
    "        return \"No Address Found\"\n",
    "    data = {'lat':location['lat'], 'lng':location['lng']}\n",
    "    # printing latitude and longitude\n",
    "    #print(\"Latitude = \", location.latitude, \"\\n\")\n",
    "    #print(\"Longitude = \", location.longitude)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(i,tree):\n",
    "    try:\n",
    "        container = tree.xpath(\"//div[@class='LbPSX']\")[0]\n",
    "        review_container = tree.xpath(\"//div[@class='LbPSX']\")\n",
    "        for details in review_container:\n",
    "            user_container = details.xpath(\".//span[@class='biGQs _P fiohW fOtGX']/a/text()\")[0]\n",
    "            user.append(clean_text(user_container))\n",
    "            #print(\"user:\",user)\n",
    "            rating_container = details.xpath(\".//div/svg[@class='UctUV d H0']\")[0]\n",
    "            user_rating.append(float(clean_text(rating_container.get('aria-label')).replace('_of_5_bubbles','')))\n",
    "            #print(\"Rating:\",user_rating)\n",
    "            review_date.append(details.xpath(\".//div/div[@class='biGQs _P pZUbB ncFvv osNWb']/text()\")[0].replace('Written ',''))\n",
    "            #print(\"review date:\", review_date)\n",
    "            review.append(details.xpath(\".//div[@class='biGQs _P fiohW qWPrE ncFvv fOtGX']/a/span[@class='yCeTE']/text()\")[0]+\\\n",
    "            '. '+details.xpath(\".//div[@class='biGQs _P pZUbB KxBGd']/span[@class='yCeTE']/text()\")[0])\n",
    "            #print(\"review:\", review)\n",
    "            attraction_id.append(i)\n",
    "\n",
    "\n",
    "        if container.xpath(\".//div[@class = 'UCacc']/a[@aria-label='Next page']/@href\"):\n",
    "            sleep(5)\n",
    "            #page_no = container.xpath(\".//div[@class = 'nsTKv']/a[@class='BrOJk u j z _F wSSLS tIqAi iNBVo']/span[@class='kLqdM']/span/text()\")[0]\n",
    "            page_no = container.xpath(\".//div[@class = 'nsTKv']/button[@class='BrOJk u j z _F wSSLS tIqAi iNBVo SSqtP']\")[0].get('aria-label')\n",
    "    \n",
    "            print(\"log: getting reviews for attraction \"+str(i)+\"- page \"+page_no)\n",
    "            link = \"https://www.getyourguide.com\" + container.xpath(\".//div[@class = 'UCacc']/a[@aria-label='Next page']/@href\")[0]\n",
    "            print(link)\n",
    "            payload = {'api_key': 'df7f9086cf5542cdcb5160d17b6fb827', 'url': link}\n",
    "            page = requests.get('http://api.scraperapi.com', params=payload)\n",
    "            #page = requests.get(link)\n",
    "            html = page.content\n",
    "            tree = lh.fromstring(html)\n",
    "            get_reviews(i, tree)\n",
    "    \n",
    "    except:\n",
    "        error_file.write(str.encode(\"error: reviews for attraction \"+str(i)+\" could not be extracted\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(i,url, maps_key):\n",
    "    try:\n",
    "        payload = {'api_key': 'df7f9086cf5542cdcb5160d17b6fb827', 'url': url}\n",
    "        page = requests.get('http://api.scraperapi.com', params=payload)\n",
    "        html = page.content\n",
    "        tree = lh.fromstring(html)\n",
    "\n",
    "\n",
    "        #geo = tree.xpath(\"//ul[@class = 'breadcrumbs']\")[0]\n",
    "        geo = tree.xpath(\"//div[@data-automation = 'breadcrumbs']\")[0]\n",
    "        try:\n",
    "            country.append(clean_text(geo.xpath(\".//div[2]/a/span/span/text()\")[0]))\n",
    "            province.append(clean_text(geo.xpath(\".//div[3]/a/span/span/text()\")[0]))\n",
    "            city.append(clean_text(geo.xpath(\".//div[4]/a/span/span/text()\")[0]))\n",
    "            #print(\"country\", country, province, city)\n",
    "        except:\n",
    "            print(\"error1\")\n",
    "            country.append(\"spain\")\n",
    "            city.append(\"nil\")\n",
    "            province.append(\"nil\")   \n",
    "            \n",
    "        try:\n",
    "            #address = tree.xpath(\"//div[@class='tyUdl']/ul/li[@class='seKux _d _c']/span[@class='biGQs _P pZUbB KxBGd']/text()\")[0]\n",
    "            address = tree.xpath(\"//div[@class='biGQs _P fiohW qWPrE ncFvv EVnyE']/text()\")[0] \n",
    "            #address = tree.xpath(\"//span[@class='biGQs _P pZUbB hmDzD']/div[@class='Ci']/text()\")[0]+\", \"+country[-1]\n",
    "            #print(\"address: \", address)\n",
    "            data = get_address(address, city[-1],country[-1])\n",
    "            location.append(data)\n",
    "            #print(\"location:\", location)\n",
    "        except:\n",
    "            location.append(\"nil\")\n",
    "        try:\n",
    "            details = tree.xpath(\"//div[@class='biGQs _P fiohW qWPrE ncFvv EVnyE']/text()\")[0]  \n",
    "            name.append(details)\n",
    "            #print(\"name:\", name)\n",
    "        except:\n",
    "            name.append(\"nil\")\n",
    "        try:\n",
    "            rating.append(float(clean_text(tree.xpath(\"//div[@class='biGQs _P fiohW hzzSG uuBRH']/text()\")[0])))\n",
    "        except:\n",
    "            rating.append(float(-1))\n",
    "        try:\n",
    "            price.append(float(clean_text(tree.xpath(\"//div[@class='biGQs _P fiohW hzzSG eIegw']/text()\")[0])[1:]))\n",
    "            #print(\"Price:\", price)\n",
    "        except:\n",
    "            price.append(float(-1))\n",
    "        \n",
    "        att_id.append(i)\n",
    "        \n",
    "        print(\"log: getting reviews for attraction \"+str(i))\n",
    "        get_reviews(i,tree)\n",
    "    \n",
    "    except:\n",
    "        error_file.write(str.encode(\"error: Details of the attraction \"+str(i)+\" could not be extracted\\n\"))\n",
    "        error_file.write(str.encode(url+\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "log: collecting details for attraction 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Michel\\scrap\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'url'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog: collecting details for attraction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m---> 24\u001b[0m     extract_info(i,\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[i],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAIzaSyC2jxjbR_svb9EjCeMBivCNEcCaaxdEYIA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m error_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Michel\\scrap\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Michel\\scrap\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'url'"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('outputss/attraction_cat.json',orient='records') \n",
    "df['attraction_id'] = df.index\n",
    "df = df.rename(index=str,columns={\"attraction\": \"url\"})\n",
    "#outputss\\attraction_cat.json\n",
    "att_id = list()\n",
    "country = list()\n",
    "province = list()\n",
    "city = list()\n",
    "location = list()\n",
    "name = list()\n",
    "rating = list()\n",
    "price = list()\n",
    "\n",
    "attraction_id = list()\n",
    "user = list()\n",
    "review = list()\n",
    "user_rating = list()\n",
    "review_date = list()\n",
    "\n",
    "error_file = open(\"outputss/error_log.txt\",\"wb\")\n",
    "print(df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    print(\"log: collecting details for attraction \"+str(i))\n",
    "    extract_info(i,df['url'][i],'AIzaSyC2jxjbR_svb9EjCeMBivCNEcCaaxdEYIA')\n",
    "error_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details dataframe verification:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'country' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails dataframe verification:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mcountry\u001b[49m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(province))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(city))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'country' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Details dataframe verification:\")\n",
    "print(len(country))\n",
    "print(len(province))\n",
    "print(len(city))\n",
    "print(len(name))\n",
    "print(len(rating))\n",
    "print(len(price))\n",
    "print(len(location))\n",
    "att_df = pd.DataFrame({'attraction_id':att_id,\n",
    "                   'name':name,\n",
    "                   'country':country,\n",
    "                   'province':province,\n",
    "                   'city':city,\n",
    "                   'location':location,\n",
    "                   'price':price,\n",
    "                   'rating':rating})\n",
    "att_df.to_json('outputss/attractions_details_batch2.json',orient='records',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews dataframe verification\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'attraction_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReviews dataframe verification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mattraction_id\u001b[49m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(user))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(review))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'attraction_id' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Reviews dataframe verification\")\n",
    "print(len(attraction_id))\n",
    "print(len(user))\n",
    "print(len(review))\n",
    "print(len(user_rating))\n",
    "print(len(review_date))\n",
    "att_rev_df = pd.DataFrame({'attraction_id':attraction_id,\n",
    "                           'user':user,\n",
    "                           'rating':user_rating,\n",
    "                           'review':review,\n",
    "                           'review_date':review_date})\n",
    "\n",
    "att_rev_df.to_json('outputss/attractions_reviews_batch2.json',orient='records',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
